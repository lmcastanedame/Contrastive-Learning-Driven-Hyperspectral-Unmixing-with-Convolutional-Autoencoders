{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_SAD(y_true, y_pred):\n",
    "    return np.arccos(y_pred.dot(y_true) / (np.linalg.norm(y_true) * np.linalg.norm(y_pred)))\n",
    "\n",
    "def order_endmembers(endmembers, endmembersGT):\n",
    "    num_endmembers = endmembers.shape[0]\n",
    "    dict = {}\n",
    "    sad_mat = np.ones((num_endmembers, num_endmembers))\n",
    "    for i in range(num_endmembers):\n",
    "        endmembers[i, :] = endmembers[i, :] / endmembers[i, :].max()\n",
    "        endmembersGT[i, :] = endmembersGT[i, :] / endmembersGT[i, :].max()\n",
    "    for i in range(num_endmembers):\n",
    "        for j in range(num_endmembers):\n",
    "            sad_mat[i, j] = numpy_SAD(endmembers[i, :], endmembersGT[j, :])\n",
    "    rows = 0\n",
    "    while rows < num_endmembers:\n",
    "        minimum = sad_mat.min()\n",
    "        index_arr = np.where(sad_mat == minimum)\n",
    "        if len(index_arr) < 2:\n",
    "            break\n",
    "        index = (index_arr[0][0], index_arr[1][0])\n",
    "        if index[0] in dict.keys():\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "        elif index[1] in dict.values():\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "        else:\n",
    "            dict[index[0]] = index[1]\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "            rows += 1\n",
    "    ASAM = 0\n",
    "    num = 0\n",
    "    for i in range(num_endmembers):\n",
    "        if np.var(endmembersGT[dict[i]]) > 0:\n",
    "            ASAM = ASAM + numpy_SAD(endmembers[i, :], endmembersGT[dict[i]])\n",
    "            num += 1\n",
    "\n",
    "    return dict, ASAM / float(num)\n",
    "\n",
    "# Function to calculate SAD between two endmember vectors\n",
    "def calculate_sad(endmember1, endmember2):\n",
    "    endmember1 = endmember1 / np.linalg.norm(endmember1)\n",
    "    endmember2 = endmember2 / np.linalg.norm(endmember2)\n",
    "    sad_value = np.arccos(np.clip(np.dot(endmember1, endmember2), -1.0, 1.0))\n",
    "    return sad_value\n",
    "\n",
    "# Function to find the optimal ordering of predicted endmembers using SAD\n",
    "def match_abundances(predicted, true):\n",
    "    num = true.shape[2]\n",
    "    cost_matrix = np.zeros((num, num))\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            cost_matrix[i, j] = mean_squared_error(predicted[:, :, i], true[:, :, j])\n",
    "    # print(cost_matrix)\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    reordered_predicted = predicted[col_ind]\n",
    "    return reordered_predicted, row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Samson\n",
      "Processing dataset: Urban4\n",
      "Processing dataset: Urban5\n",
      "Processing dataset: Urban6\n",
      "Processing dataset: Cuprite_fixed\n",
      "Processing dataset: JasperRidge\n",
      "         Dataset                               Experiment  \\\n",
      "0         Samson  Results (25 runs, no seed, diff images)   \n",
      "1         Samson  Results (25 runs, no seed, diff images)   \n",
      "2         Samson  Results (25 runs, no seed, diff images)   \n",
      "3         Samson  Results (25 runs, no seed, diff images)   \n",
      "4         Samson  Results (25 runs, no seed, diff images)   \n",
      "..           ...                                      ...   \n",
      "319  JasperRidge     Results (25 runs, seed, same images)   \n",
      "320  JasperRidge     Results (25 runs, seed, same images)   \n",
      "321  JasperRidge     Results (25 runs, seed, same images)   \n",
      "322  JasperRidge     Results (25 runs, seed, same images)   \n",
      "323  JasperRidge     Results (25 runs, seed, same images)   \n",
      "\n",
      "                        Folder  \\\n",
      "0    Blur (sigma = [0.1, 1.0])   \n",
      "1    Blur (sigma = [0.1, 2.0])   \n",
      "2                    Crop (50)   \n",
      "3                    Crop (75)   \n",
      "4                    Crop (95)   \n",
      "..                         ...   \n",
      "319              Crop + Jitter   \n",
      "320       Crop + Jitter + Blur   \n",
      "321       Crop + Jitter + Flip   \n",
      "322              Jitter + Flip   \n",
      "323       Jitter + Flip + Blur   \n",
      "\n",
      "                                           Average_SAD  \\\n",
      "0               [0.07489481, 0.041711632, 0.021508552]   \n",
      "1                [0.05085009, 0.03963101, 0.020484393]   \n",
      "2              [0.053257085, 0.041059345, 0.028172707]   \n",
      "3               [0.047364272, 0.04020083, 0.031254176]   \n",
      "4                 [0.05538568, 0.04096571, 0.02837256]   \n",
      "..                                                 ...   \n",
      "319  [0.039370444, 0.058137912, 0.0932933, 0.37420258]   \n",
      "320   [0.039539754, 0.061789747, 0.07585076, 0.378521]   \n",
      "321  [0.05035397, 0.045888692, 0.12229678, 0.39209083]   \n",
      "322   [0.04719847, 0.05215435, 0.11024978, 0.39994562]   \n",
      "323  [0.048922606, 0.045409095, 0.11976977, 0.36391...   \n",
      "\n",
      "                                 Average_MSE  \\\n",
      "0    [0.036765113, 0.020463748, 0.013785843]   \n",
      "1     [0.03147985, 0.017021328, 0.013590615]   \n",
      "2     [0.033755686, 0.01888244, 0.013597596]   \n",
      "3     [0.03099151, 0.016752927, 0.012934601]   \n",
      "4    [0.033989333, 0.019005323, 0.013476241]   \n",
      "..                                       ...   \n",
      "319                                     None   \n",
      "320                                     None   \n",
      "321                                     None   \n",
      "322                                     None   \n",
      "323                                     None   \n",
      "\n",
      "                                               STD_SAD  \\\n",
      "0              [0.12481445, 0.008155554, 0.0035664225]   \n",
      "1             [0.027851084, 0.0014223419, 0.002636511]   \n",
      "2             [0.027224211, 0.0018317377, 0.004070193]   \n",
      "3            [0.013911472, 0.0012329167, 0.0057024853]   \n",
      "4            [0.031172998, 0.0020718465, 0.0051669055]   \n",
      "..                                                 ...   \n",
      "319  [0.0029061877, 0.0072773257, 0.021223996, 0.08...   \n",
      "320  [0.0029846355, 0.010990431, 0.016233327, 0.026...   \n",
      "321  [0.006574235, 0.008898486, 0.02188459, 0.05592...   \n",
      "322  [0.0024289687, 0.009869329, 0.009008743, 0.005...   \n",
      "323  [0.0026011544, 0.0085417265, 0.028073853, 0.07...   \n",
      "\n",
      "                                       STD_MSE  \n",
      "0      [0.02554134, 0.015087835, 0.0056555695]  \n",
      "1    [0.006631363, 0.0051441276, 0.0023906298]  \n",
      "2     [0.009107387, 0.006959101, 0.0022341234]  \n",
      "3     [0.008637115, 0.006328253, 0.0024284427]  \n",
      "4     [0.008106371, 0.0053266357, 0.003032586]  \n",
      "..                                         ...  \n",
      "319                                       None  \n",
      "320                                       None  \n",
      "321                                       None  \n",
      "322                                       None  \n",
      "323                                       None  \n",
      "\n",
      "[324 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of folders/experiments (you can add more folders as needed)\n",
    "folder_names = [\n",
    "    # 'Original Results',\n",
    "    'Blur (sigma = [0.1, 1.0])',\n",
    "    'Blur (sigma = [0.1, 2.0])',\n",
    "    'Crop (50)',\n",
    "    'Crop (75)',\n",
    "    'Crop (95)',\n",
    "    'Vertical Flip',\n",
    "    'Horizontal Flip',\n",
    "    'Mix Flip',\n",
    "    'Random Flip',\n",
    "    'Jitter', \n",
    "    'Crop + Blur',\n",
    "    'Crop + Flip',\n",
    "    'Crop + Flip + Blur',\n",
    "    'Crop + Jitter',\n",
    "    'Crop + Jitter + Blur',\n",
    "    'Crop + Jitter + Flip',\n",
    "    'Jitter + Flip',\n",
    "    'Jitter + Flip + Blur',\n",
    "]\n",
    "\n",
    "exp_names = [\n",
    "    # '',\n",
    "    'Results (25 runs, no seed, diff images)',\n",
    "    'Results (25 runs, no seed, same images)',\n",
    "    'Results (25 runs, seed, same images)'\n",
    "]\n",
    "\n",
    "datasetnames = {\n",
    "    'Samson': {\n",
    "        'num_endmembers': 3,\n",
    "    },\n",
    "    'Urban4': {\n",
    "        'num_endmembers': 4,\n",
    "    },\n",
    "    'Urban5': {\n",
    "        'num_endmembers': 5,\n",
    "    },\n",
    "    'Urban6': {\n",
    "        'num_endmembers': 6,\n",
    "    },\n",
    "    'Cuprite_fixed': {\n",
    "        'num_endmembers': 12,\n",
    "    },\n",
    "    'JasperRidge': {\n",
    "        'num_endmembers': 4,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Variables to store results for each folder\n",
    "results = []\n",
    "\n",
    "# Loop over each dataset\n",
    "for dataset in datasetnames:\n",
    "    \n",
    "    print(f'Processing dataset: {dataset}')\n",
    "\n",
    "    path = \"./Datasets/\" + dataset + \".mat\"\n",
    "\n",
    "    try:\n",
    "        data = sio.loadmat(path)\n",
    "    except NotImplementedError:\n",
    "        data = hdf.File(path, 'r')\n",
    "\n",
    "    Y = np.asarray(data['Y'], dtype=np.float32)\n",
    "    GT = np.asarray(data['GT'], dtype=np.float32)\n",
    "    if Y.shape[0] < Y.shape[1]:\n",
    "        Y = Y.transpose()\n",
    "    Y = Y / np.max(Y.flatten())\n",
    "    n_bands = Y.shape[1]\n",
    "    n_rows = data['lines'].item()\n",
    "    n_cols = data['cols'].item()\n",
    "    Y = np.reshape(Y, (n_cols, n_rows, n_bands))\n",
    "    \n",
    "    if 'S_GT' in data.keys():\n",
    "        S_GT = np.asarray(data['S_GT'], dtype=np.float32)\n",
    "    else:\n",
    "        S_GT = None\n",
    "    \n",
    "    num_endmembers = datasetnames[dataset]['num_endmembers']\n",
    "\n",
    "    n = num_endmembers // 2  # how many digits we will display\n",
    "\n",
    "    # Loop over each experiment folder \n",
    "    for exp in exp_names:\n",
    "\n",
    "        # Loop over each folder and process the results\n",
    "        for folder in folder_names:\n",
    "            \n",
    "            # Path template for the current folder (assuming 25 runs per folder)\n",
    "            mat_file_template = f'./{dataset}/90 images/{exp}/{folder}/results_run_{{}}.mat'  # Path template for .mat files\n",
    "            # mat_file_template = f'./Results/CNNAEU/{dataset}/synthetic_run{{}}.mat_run{{}}.mat'  # Path template for .mat files\n",
    "            \n",
    "            sad_values_per_run = []\n",
    "            mse_values_per_run = []\n",
    "\n",
    "            num_runs = 25\n",
    "                \n",
    "            for i in range(num_runs):\n",
    "                # Load the .mat file for each run\n",
    "                mat_file_path = mat_file_template.format(i + 1)\n",
    "                # mat_file_path = mat_file_template.format(i, i + 1)\n",
    "                \n",
    "                # Check if the file exists before attempting to load\n",
    "                if not os.path.exists(mat_file_path):\n",
    "                    # If the file doesn't exist, skip this iteration\n",
    "                    continue\n",
    "        \n",
    "                data = sio.loadmat(mat_file_path)\n",
    "                \n",
    "                predicted_endmembers = data.get('endmembers').T  # Predicted endmembers from the autoencoder\n",
    "                # predicted_endmembers = data.get('M')  # Predicted endmembers from the autoencoder\n",
    "                true_endmembers = GT  # Ground truth endmembers\n",
    "                num_endmembers = true_endmembers.shape[0]\n",
    "\n",
    "                for m in range(num_endmembers):\n",
    "                    predicted_endmembers[m, :] = predicted_endmembers[m, :] / predicted_endmembers[m, :].max()\n",
    "                    true_endmembers[m, :] = true_endmembers[m, :] / true_endmembers[m, :].max()\n",
    "                \n",
    "                if predicted_endmembers is not None and true_endmembers is not None:\n",
    "                    order_dict, _ = order_endmembers(true_endmembers, predicted_endmembers)\n",
    "\n",
    "                    reordered_predicted_endmembers = predicted_endmembers[[order_dict[k] for k in sorted(order_dict.keys())]]\n",
    "                    \n",
    "                    run_sad_values = []\n",
    "                    # Calculate SAD for each matched endmember pair\n",
    "                    for j in range(true_endmembers.shape[0]):\n",
    "                        sad_value = numpy_SAD(true_endmembers[j], reordered_predicted_endmembers[j])\n",
    "                        run_sad_values.append(sad_value)\n",
    "                    \n",
    "                    sad_values_per_run.append(run_sad_values)\n",
    "                \n",
    "                predicted_abundances = data.get('abundances')  # Predicted abundances\n",
    "                # predicted_abundances = data.get('A')  # Predicted abundances\n",
    "                true_abundances = S_GT  # Ground truth abundances\n",
    "                \n",
    "                if predicted_abundances is not None and true_abundances is not None:\n",
    "                    run_mse_values = []\n",
    "                    reordered_predicted_abundances = predicted_abundances[:, :, [order_dict[i] for i in sorted(order_dict.keys())]]\n",
    "                    for l in range(true_abundances.shape[2]):\n",
    "                        mse_value = mean_squared_error(reordered_predicted_abundances[:, :, l], true_abundances[:, :, l].T)\n",
    "                        run_mse_values.append(mse_value)\n",
    "                    \n",
    "                    mse_values_per_run.append(run_mse_values)\n",
    "\n",
    "            # Compute average and standard deviation for SAD and MSE\n",
    "            average_sad_per_endmember = np.mean(sad_values_per_run, axis=0) if sad_values_per_run else None\n",
    "            average_mse_per_abundance = np.mean(mse_values_per_run, axis=0) if mse_values_per_run else None\n",
    "            std_sad_per_endmember = np.std(sad_values_per_run, axis=0) if sad_values_per_run else None\n",
    "            std_mse_per_abundance = np.std(mse_values_per_run, axis=0) if mse_values_per_run else None\n",
    "            \n",
    "            # Store the results for this folder\n",
    "            results.append({\n",
    "                'Dataset': dataset,\n",
    "                'Experiment': exp,\n",
    "                'Folder': folder,\n",
    "                'Average_SAD': average_sad_per_endmember,\n",
    "                'Average_MSE': average_mse_per_abundance,\n",
    "                'STD_SAD': std_sad_per_endmember,\n",
    "                'STD_MSE': std_mse_per_abundance\n",
    "            })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, you can save the DataFrame to a CSV file\n",
    "# results_df.to_csv('original_results_last_datasets.csv', index=False)\n",
    "results_df.to_csv('comparison_results_90_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid SAD results and align with folder names\n",
    "sad_boxplot_data = []\n",
    "sad_labels = []\n",
    "\n",
    "for i, sad_data in enumerate(results_df['Average_SAD']):\n",
    "    if sad_data is not None:\n",
    "        try:\n",
    "            # Ensure sad_data is iterable and valid\n",
    "            sad_boxplot_data.append(sad_data)  # Append SAD data (full list, not mean here)\n",
    "            sad_labels.append(results_df['Folder'].iloc[i])  # Append corresponding folder name\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing SAD data for index {i}: {e}\")\n",
    "\n",
    "# Check lengths of data and labels\n",
    "print(f\"Number of boxplot data points: {len(sad_boxplot_data)}\")\n",
    "print(f\"Number of labels: {len(sad_labels)}\")\n",
    "\n",
    "# Ensure lengths match\n",
    "if len(sad_boxplot_data) != len(sad_labels):\n",
    "    print(\"Mismatch detected between data and labels! Fixing...\")\n",
    "    min_length = min(len(sad_boxplot_data), len(sad_labels))\n",
    "    sad_boxplot_data = sad_boxplot_data[:min_length]\n",
    "    sad_labels = sad_labels[:min_length]\n",
    "\n",
    "# Plot SAD boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(sad_boxplot_data, tick_labels=sad_labels, showmeans=True)  # Using tick_labels for compatibility\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('SAD Distribution Across Folders (25 runs, no seed, diff images per run)')\n",
    "plt.ylabel('SAD')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid MSE results and align with folder names\n",
    "mse_boxplot_data = []\n",
    "mse_labels = []\n",
    "\n",
    "for i, mse_data in enumerate(results_df['Average_MSE']):\n",
    "    if mse_data is not None:\n",
    "        try:\n",
    "            # Ensure mse_data is iterable and valid\n",
    "            mse_boxplot_data.append(mse_data)  # Append MSE data (full list, not mean here)\n",
    "            mse_labels.append(results_df['Folder'].iloc[i])  # Append corresponding folder name\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing MSE data for index {i}: {e}\")\n",
    "\n",
    "# Check lengths of data and labels\n",
    "print(f\"Number of boxplot data points: {len(mse_boxplot_data)}\")\n",
    "print(f\"Number of labels: {len(mse_labels)}\")\n",
    "\n",
    "# Ensure lengths match\n",
    "if len(mse_boxplot_data) != len(mse_labels):\n",
    "    print(\"Mismatch detected between data and labels! Fixing...\")\n",
    "    min_length = min(len(mse_boxplot_data), len(mse_labels))\n",
    "    mse_boxplot_data = mse_boxplot_data[:min_length]\n",
    "    mse_labels = mse_labels[:min_length]\n",
    "\n",
    "# Plot MSE boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(mse_boxplot_data, tick_labels=mse_labels, showmeans=True)  # Using tick_labels for compatibility\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('MSE Distribution Across Folders (25 runs, no seed, diff images per run)')\n",
    "plt.ylabel('MSE')\n",
    "plt.tight_layout()\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_predicted_endmembers(predicted_endmembers, true_endmembers):\n",
    "    \"\"\"\n",
    "    Reorder predicted endmembers to match the true endmembers based on the `order_endmembers` function.\n",
    "    \n",
    "    Parameters:\n",
    "        predicted_endmembers (numpy array): Predicted endmember matrix (num_endmembers, num_bands).\n",
    "        true_endmembers (numpy array): True endmember matrix (num_endmembers, num_bands).\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: Reordered predicted endmembers.\n",
    "    \"\"\"\n",
    "    order_dict, _ = order_endmembers(true_endmembers, predicted_endmembers)\n",
    "    reordered_endmembers = predicted_endmembers[[order_dict[k] for k in sorted(order_dict.keys())], :]\n",
    "    return reordered_endmembers\n",
    "\n",
    "def plot_all_endmembers(true_endmembers, predicted_endmembers_list, augmentation_name):\n",
    "    \"\"\"\n",
    "    Create a subplot for all 4 endmembers comparing true vs. predicted endmembers.\n",
    "    \n",
    "    Parameters:\n",
    "        true_endmembers (numpy array): True endmember matrix (num_endmembers, num_bands).\n",
    "        predicted_endmembers_list (list of numpy arrays): List of predicted endmembers for multiple runs.\n",
    "        augmentation_name (str): Name of the augmentation or experiment.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_endmembers = true_endmembers.shape[0]\n",
    "    plt.figure(figsize=(16, 10))  # Adjust size for readability\n",
    "\n",
    "    for endmember_index in range(num_endmembers):\n",
    "        plt.subplot(3, 2, endmember_index + 1)  # Create a 2x2 grid of subplots\n",
    "        \n",
    "        # Plot the true endmember\n",
    "        plt.plot(true_endmembers[endmember_index] / np.max(true_endmembers[endmember_index]), \n",
    "                 label='True Endmember', linewidth=2, color='black')\n",
    "        \n",
    "        # Plot all reordered predicted endmembers for this index\n",
    "        for i, predicted_endmembers in enumerate(predicted_endmembers_list):\n",
    "            normalized_endmember = predicted_endmembers[endmember_index] / np.max(predicted_endmembers[endmember_index])\n",
    "            plt.plot(normalized_endmember, linestyle='--', alpha=0.7, label=f'Run {i + 1}' if i < 5 else \"\")  # Limit legend\n",
    "        \n",
    "        plt.title(f'Endmember {endmember_index + 1}')\n",
    "        plt.xlabel('Spectral Band')\n",
    "        plt.ylabel('Normalized Reflectance')\n",
    "        if endmember_index == 0:  # Add legend only for the first plot\n",
    "            plt.legend(loc='best', fontsize='small')\n",
    "    \n",
    "    plt.suptitle(f'Variation of Predicted Endmembers Across Runs ({augmentation_name})', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout for the main title\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "path = \"./Datasets/Urban5.mat\"\n",
    "\n",
    "try:\n",
    "    data_org = sio.loadmat(path)\n",
    "except NotImplementedError:\n",
    "    data_org = hdf.File(path, 'r')\n",
    "\n",
    "Y = np.asarray(data_org['Y'], dtype=np.float32)\n",
    "GT = np.asarray(data_org['GT'], dtype=np.float32)\n",
    "\n",
    "true_endmembers = GT\n",
    "\n",
    "num_runs = 25\n",
    "\n",
    "# Example usage\n",
    "augmentation_name = \"Vertical Flip\"\n",
    "predicted_endmembers_list = []  # Replace with a list of predicted endmember matrices from multiple runs\n",
    "\n",
    "# Add predicted endmembers from each run to the list\n",
    "for i in range(num_runs):\n",
    "    mat_file_path = f'./Urban5/10 images/Results (25 runs, no seed, diff images)/{augmentation_name}/results_run_{i + 1}.mat'\n",
    "    data = sio.loadmat(mat_file_path)\n",
    "    predicted_endmembers = data.get('endmembers').T  # Assuming this is your predicted endmember matrix\n",
    "    \n",
    "    # Reorder predicted endmembers to match true endmembers\n",
    "    reordered_predicted_endmembers = reorder_predicted_endmembers(predicted_endmembers, true_endmembers)\n",
    "    \n",
    "    # Normalize each reordered endmember\n",
    "    for m in range(reordered_predicted_endmembers.shape[0]):\n",
    "        reordered_predicted_endmembers[m, :] = reordered_predicted_endmembers[m, :] / np.max(reordered_predicted_endmembers[m, :])\n",
    "    \n",
    "    predicted_endmembers_list.append(reordered_predicted_endmembers)\n",
    "\n",
    "# Normalize true endmembers\n",
    "for m in range(true_endmembers.shape[0]):\n",
    "    true_endmembers[m, :] = true_endmembers[m, :] / np.max(true_endmembers[m, :])\n",
    "\n",
    "# Plot all 4 endmembers in subplots\n",
    "plot_all_endmembers(true_endmembers, predicted_endmembers_list, augmentation_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNNAEU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
